# HR Hiring Bot â€” Full Documentation

---

##  Project Title

**HR Hiring Bot** â€” AIâ€‘Powered Resume Screening, JD Understanding, and Candidate Ranking System

---

##  Overview

The **HR Hiring Bot** automates endâ€‘toâ€‘end resume evaluation against job descriptions using **LLMs + Embeddings + ATSâ€‘style keyword matching**. It ensures unbiased, consistent, explainable and scalable hiring assistance.

The system:

* Converts **Job Descriptions (JD)** into structured machineâ€‘understandable JSON
* Parses **PDF resumes** into structured JSON with projects, metrics, skills & domain tags
* Scores each candidate based on **Project relevance, Keyword match and Semantic understanding**
* Produces **ranked candidate lists** with complete explainability
* Provides an easyâ€‘toâ€‘use **Streamlit UI** for HR teams

---

##  Core Objective

| Goal              | Implementation                                                                         |
| ----------------- | -------------------------------------------------------------------------------------- |
| Understand JD     | LLMâ€‘based parser (JDGpt.py) â†’ `JD.json` (role, seniority, domain tags, weighting etc.) |
| Understand Resume | LLMâ€‘based parser (GptJson.py) â†’ detailed resume JSON                                   |
| Compare Fairly    | Hybrid Ranking = Project + Semantic + Keyword                                          |
| Explainability    | Provenance spans + sectionâ€‘level semantic matches                                      |
| HR Usability      | Streamlit UI + Downloadable rankings                                                   |

---

##  System Features

ðŸ”¹ JD â†’ JSON (no information loss, adds inferred domain, seniority, HR notes)

ðŸ”¹ Resume â†’ JSON (projects with metrics, canonical skills, inferred skills, domain tags)

ðŸ”¹ Multiâ€‘stage scoring:

* **KeywordComparitor** â†’ ATSâ€‘style weighted matching
* **ProjectProcess** â†’ projectâ€‘depth & domainâ€‘match scoring
* **SemanticComparitor** â†’ OpenAI embedding deepâ€‘match

ðŸ”¹ **FinalRanking** â€” ensures **no candidate is skipped unless all scores = 0**

ðŸ”¹ **RAMâ€‘safe UI ranking** â€” shown even if cloud host blocks file write

ðŸ”¹ **PDF handling fallback system** â€” PyMuPDF â†’ PyPDF2 â†’ regex fallback

---

##  Tech Stack

| Layer             | Tools / Libraries                                    |
| ----------------- | ---------------------------------------------------- |
| UI                | Streamlit                                            |
| LLM Parsing       | OpenAI GPTâ€‘4oâ€‘mini (function calling)                |
| Semantic Matching | OpenAI Embeddings â€” `textâ€‘embeddingâ€‘3â€‘small`         |
| Caching           | Pickle cache for embeddings                          |
| PDF Extraction    | PyMuPDF (fitz), PyPDF2 with fallback router          |
| Data Processing   | Python, NumPy, JSON                                  |
| Orchestration     | runpy (no subprocess) for Streamlit execution safety |

>  Heavy libraries like `torch` / sentenceâ€‘transformers were removed for deployment compatibility.

---

##  Repository Structure

```
HR_Hiring_Bot/
â”‚ main.py                        â†’ Streamlit UI + pipeline orchestration
â”‚ requirements.txt
â”‚ README.md
â”‚
â”œâ”€ InputThread/
â”‚   â”œâ”€ JD/
â”‚   â”‚   â”œâ”€ JD.txt              â†’ Raw uploaded JD
â”‚   â”‚   â”œâ”€ JD.json             â†’ Structured normalized JD
â”‚   â”œâ”€ AI Processing/
â”‚   â”‚   â”œâ”€ JDGpt.py            â†’ JD â†’ JSON using LLM
â”‚   â”‚   â”œâ”€ GptJson.py          â†’ Resume â†’ JSON using LLM
â”‚   â”œâ”€ file_router.py          â†’ Picks best PDF extraction method
â”‚   â”œâ”€ extract_pdf.py          â†’ PDF extraction engines
â”‚
â”œâ”€ ResumeProcessor/
â”‚   â”œâ”€ ProjectProcess.py       â†’ Project depth + metrics scoring
â”‚   â”œâ”€ KeywordComparitor.py    â†’ ATS weighted keyword matching
â”‚   â”œâ”€ SemanticComparitor.py   â†’ Embedding similarity matching
â”‚   â””â”€ Ranker/
â”‚       â”œâ”€ FinalRanking.py     â†’ Final ranking aggregation & RAM export
â”‚
â”œâ”€ Processed-TXT/              â†’ Extracted raw PDF text
â”œâ”€ ProcessedJson/              â†’ LLM generated structured resume JSON
â”œâ”€ Ranking/
â”‚   â”œâ”€ Scores.json             â†’ Consolidated scores across all modules
â”‚   â”œâ”€ Final_Ranking.json      â†’ Sorted ranking with final scores
â”‚   â”œâ”€ DisplayRanks.txt        â†’ HR readable list (Name | Score)
â”‚   â””â”€ Skipped.json            â†’ Only resumes with **all scores = 0**
```

---

##  Complete Candidate Evaluation Pipeline

### **ðŸ”¹ Step 1: Upload JD â†’ Run JDGpt.py**

* Accepts PDF or pasted text
* Extracted â†’ `JD.txt`
* LLM produces `JD.json` containing:

```
role_title, seniority_level, domain_tags, weighting,
required_skills, preferred_skills,
embedding_hints, hr_notes, hr_points, meta
```

> `domain_tags` is later used by resume parser for **domainâ€‘relevant scoring**.

### **ðŸ”¹ Step 2: Upload Resumes â†’ route_pdf() â†’ GptJson.py**

* Raw text saved to `/Processed-TXT`
* LLM produces structured `/ProcessedJson/*.json` with:

```
name, canonical_skills, inferred_skills,
projects (with metrics, tech, responsibilities),
experience_entries, profile_keywords_line,
domain_tags, ats_boost_line, provenance
```

### **ðŸ”¹ Step 3: ProjectProcess.py â†’ project_aggregate**

* Evaluates each project for:

  * technical complexity
  * execution quality
  * outcome/metrics
  * domain alignment with JD

### **ðŸ”¹ Step 4: KeywordComparitor.py â†’ Keyword_Score**

* Weighted ATSâ€‘style matching using:

```
required_skills
preferred_skills
weighted_keywords
experience_keywords
certifications
education
```

* Handles resume errors safely â†’ if issue â†’ assign `Keyword_Score = 0` and continue

### **ðŸ”¹ Step 5: SemanticComparitor.py â†’ Semantic_Score**

* OpenAI embeddings cache â†’ fast reâ€‘runs
* Sectionâ€‘level similarity for:

```
profile, skills, projects, responsibilities, education, overall
```

* Normalizes scores across all candidates

### **ðŸ”¹ Step 6: FinalRanking.py â†’ Final_Ranking.json**

Ranking Logic:

| Case           | Rule                        |
| -------------- | --------------------------- |
| All scores = 0 | skip                        |
| Only 1 score   | apply small decay â†’ include |
| 2 or 3 scores  | weighted normalized ranking |

Also exposes:

```
run_ranking() â†’ returns ranking in RAM for UI
RANKING_RAM   â†’ cached ranking
```

---

##  Streamlit User Flow

| Step | Action                                      |
| ---- | ------------------------------------------- |
| 1    | Upload JD (PDF or text)                     |
| 2    | Click **â€œProcess JDâ€**                      |
| 3    | Upload multiple candidate resumes (PDF)     |
| 4    | Click **â€œProcess & Rank Resumesâ€**          |
| 5    | Navigate to **ðŸ† Rankings** tab             |
| 6    | Download ranking list or use refresh button |

Even if fileâ€‘write fails on cloud hosting:
âœ” Rankings still display via `RANKING_RAM`

---

##  Output Examples

### **DisplayRanks.txt** (HR friendly)

```
1. Neeraj Jain | 0.931
2. Abhiraj Kumar Singh | 0.751
3. Mohit Patil | 0.719
...
```

### **Final_Ranking.json** (machine consumable)

```
[
  {"name": "Neeraj Jain", "Final_Score": 0.931, ...},
  {"name": "Abhiraj Kumar Singh", "Final_Score": 0.751, ...},
  ...
]
```

---

##  Requirements

```
python >= 3.10
streamlit
openai
pandas
numpy
PyPDF2
pymupdf
```

Run UI:

```
streamlit run main.py
```

---

##  Future Enhancements

* OCR support for scanned resumes
* CSV / Excel export for ranking
* ATS integrations (Greenhouse / Lever API)
* Interview scheduling automation
* Explainability dashboard (match heatmaps)

---

## ðŸ‘¤ Author

| Detail   | Info                                                                                         |
| -------- | -------------------------------------------------------------------------------------------- |
| Name     | **Harsh Chinchakar**                                                                         |

---

##  License

This project is released under the **MIT License**.

---

> Update This README continuously to reflect the latest pipeline upgrades and scoring improvements.
